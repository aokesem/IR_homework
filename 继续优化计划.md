#结果优化方面
RAG检索效果尚未评测（考虑使用ragas）
只调用了Qwen2.5 instruct，尚未尝试其他Embedding模型和LLM模型效果
未测试与其他方法共同使用的效果，如对模型进行微调或开启联网搜索功能
结合BM25和vector进行混合检索
优化分块策略，尝试父子文档检索或上下文增强
结合重排序和查询改写策略

#功能完善方面
多轮对话功能：目前的 answer_question 函数是无记忆的。还需 增加一个 history 列表，把之前的问答拼接到 Prompt 里
增加模型选择：修改 generator.py 支持 Ollama API 其他模型，在前端实现模型自由选择。
元数据过滤：当前检索是默认从全部文档中，可以依靠 FAISS 的 metadata filtering 功能进一步过滤。
解析数据缓存：系统直接从 raw 读取并在内存中处理，可将解析后的纯文本缓存到 processed 目录，下次重建索引时直接读取文本。加快加载速度
