"""
RAGé—®ç­”ç³»ç»Ÿ Webç•Œé¢
ä½¿ç”¨Gradioæ„å»ºäº¤äº’ç•Œé¢
"""
import gradio as gr
import os
import sys
from pathlib import Path
from typing import List, Tuple, Dict
import json
import time
from datetime import datetime

sys.path.append(str(Path(__file__).parent / "src"))

from src.rag_system import RAGSystem


class RAGWebApp:
    """RAG Webåº”ç”¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–Webåº”ç”¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # ç¯å¢ƒå˜é‡æ§åˆ¶è™šæ‹Ÿæ¨¡å¼å¿«é€ŸæŸ¥çœ‹å¼€å‘æ•ˆæœ
        dummy_mode = os.environ.get("RAG_DEV_MODE", "False").lower() == "true"
        self.rag_system = RAGSystem(config_path, dummy_mode=dummy_mode)
        
        # å°è¯•åŠ è½½å·²æœ‰çŸ¥è¯†åº“ (è™šæ‹Ÿæ¨¡å¼ä¸‹è·³è¿‡)
        self.kb_loaded = False
        if not dummy_mode:
            vector_store_path = self.rag_system.config['paths']['vector_store']
            if os.path.exists(vector_store_path):
                try:
                    self.rag_system.load_knowledge_base()
                    self.kb_loaded = True
                except Exception as e:
                    print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
        else:
            self.kb_loaded = True 
            
        # å¯¹è¯ä¿å­˜è·¯å¾„
        self.conv_dir = Path(self.rag_system.config['paths'].get('conversations', "data/conversations"))
        self.conv_dir.mkdir(parents=True, exist_ok=True)
        self.current_chat_file = None

    def answer_question(self,question: str,
    history: list,
    top_k: int = 5,
    custom_prompt: str = None):
        """
        å›ç­”é—®é¢˜ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ã€æ¥æºç»‘å®šåŠè‡ªå®šä¹‰ Promptï¼‰
        """

        if not self.kb_loaded:
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": "âš ï¸ çŸ¥è¯†åº“å°šæœªæ„å»ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£æˆ–é‡å»ºåº“"})
        else:
            # æŸ¥è¯¢ RAG
            result = self.rag_system.query(
                question,
                top_k=top_k,
                history=history,
                custom_prompt=custom_prompt
            )

            # æ„é€ æ¥æº HTML
            sources_html = f"\n\n<details><summary>ğŸ“‘ æŸ¥çœ‹ {result['num_sources']} ä¸ªå‚è€ƒæ¥æº</summary>\n\n"
            for i, source in enumerate(result.get('sources', []), 1):
                sources_html += f"**[èµ„æ–™{i}]** {source['file_name']} (ç›¸ä¼¼åº¦: {source['similarity'] or 'N/A'})\n"
                sources_html += f"> {source['content']}\n\n"
            sources_html += "</details>"

            full_answer = result["answer"] + sources_html

            # æŒ‰é¡ºåºå…¥è´¦
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": full_answer})
            self.save_chat(history)
            
        return history, "", gr.update(choices=self.list_chats())
    
    def save_chat(self, history: list):
        """ä¿å­˜å¯¹è¯å†å²åˆ° JSONï¼ˆmessages æ ¼å¼ï¼‰"""
        if not history:
            return

        if not self.current_chat_file:
            # æ‰¾ç¬¬ä¸€æ¡ user æ¶ˆæ¯ä½œä¸ºæ–‡ä»¶å
            first_q = "chat"
            for msg in history:
                if msg.get("role") == "user":
                    first_q = msg["content"]
                    break

            safe_first_q = (
                first_q[:15]
                .replace(" ", "_")
                .replace("?", "")
                .replace("/", "")
            )

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.current_chat_file = f"chat_{timestamp}_{safe_first_q}.json"

        filepath = self.conv_dir / self.current_chat_file
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(
                {
                    "history": history,
                    "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                },
                f,
                ensure_ascii=False,
                indent=2,
            )

            
    def list_chats(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„å¯¹è¯"""
        chats = list(self.conv_dir.glob("*.json"))
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        chats.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return [c.name for c in chats]

    def load_chat(self, filename: str) -> tuple:
        """ä»JSONåŠ è½½å¯¹è¯"""
        if not filename:
            return [], "", gr.update()
            
        self.current_chat_file = filename
        filepath = self.conv_dir / filename
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                history = data['history']
                return history, f"âœ… å·²è½½å…¥å¯¹è¯: {filename}", gr.update(value=filename)
        except Exception as e:
            return [], f"âŒ è½½å…¥å¤±è´¥: {str(e)}", gr.update()

    def handle_clear(self):
        """å¤„ç†æ¸…ç©ºå¯¹è¯"""
        self.current_chat_file = None
        return [], "", gr.update(value=None)

    def refresh_kb_list(self):
        """è·å–å¹¶æ ¼å¼åŒ–çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨"""
        if not self.kb_loaded:
            return []
        sources = self.rag_system.get_knowledge_base_sources()
        # è½¬æ¢ä¸º DataFrame æ ¼å¼éœ€è¦çš„åˆ—è¡¨
        return [[s['file_name'], s['chunk_count']] for s in sources]
    
    def build_kb_from_directory(self, progress=gr.Progress()):
        """ä»data/rawç›®å½•æ„å»ºçŸ¥è¯†åº“"""
        try:
            progress(0, desc="å¼€å§‹å¤„ç†æ–‡æ¡£...")
            
            raw_docs_path = self.rag_system.config['paths']['raw_docs']
            if not os.path.exists(raw_docs_path):
                return f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {raw_docs_path}"
            
            progress(0.3, desc="åŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£...")
            self.rag_system.build_knowledge_base()
            
            progress(1.0, desc="å®Œæˆ!")
            self.kb_loaded = True
            
            stats = self.rag_system.retriever.get_stats()
            return f"âœ… çŸ¥è¯†åº“æ„å»ºæˆåŠŸ!\næ–‡æ¡£å—æ•°é‡: {stats['document_count']}"
            
        except Exception as e:
            return f"âŒ æ„å»ºå¤±è´¥: {str(e)}"
    
    def upload_files(self, files, progress=gr.Progress()):
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“
        
        Args:
            files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        """
        if not files:
            return "è¯·é€‰æ‹©æ–‡ä»¶"
        
        try:
            progress(0, desc="å¤„ç†æ–‡ä»¶...")
            
            # ä¿å­˜æ–‡ä»¶åˆ°rawç›®å½•
            raw_docs_path = self.rag_system.config['paths']['raw_docs']
            os.makedirs(raw_docs_path, exist_ok=True)
            
            file_paths = []
            for file in files:
                file_path = os.path.join(raw_docs_path, os.path.basename(file.name))
                # å¤åˆ¶æ–‡ä»¶
                import shutil
                shutil.copy(file.name, file_path)
                file_paths.append(file_path)
            
            progress(0.5, desc="æ·»åŠ åˆ°çŸ¥è¯†åº“...")
            
            if not self.kb_loaded:
                # é¦–æ¬¡æ„å»º
                self.rag_system.build_knowledge_base()
                self.kb_loaded = True
            else:
                # æ·»åŠ åˆ°å·²æœ‰çŸ¥è¯†åº“
                self.rag_system.add_documents(file_paths)
            
            progress(1.0, desc="å®Œæˆ!")
            
            stats = self.rag_system.retriever.get_stats()
            return f"âœ… æˆåŠŸæ·»åŠ  {len(file_paths)} ä¸ªæ–‡ä»¶!\nå½“å‰æ–‡æ¡£å—æ•°é‡: {stats['document_count']}"
            
        except Exception as e:
            return f"âŒ ä¸Šä¼ å¤±è´¥: {str(e)}"
    
    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = self.rag_system.get_system_info()
        
        text = "### ç³»ç»Ÿé…ç½®\n\n"
        text += f"**Embeddingæ¨¡å‹**: {info['retriever']['embedding_model']}\n"
        text += f"**LLMæ¨¡å‹**: {info['generator']['model_name']} ({info['generator'].get('provider', 'huggingface')})\n"
        text += f"**è®¾å¤‡**: {info['generator']['device']}\n\n"
        
        text += "### æ–‡æ¡£å¤„ç†\n\n"
        text += f"**åˆ‡åˆ†å¤§å°**: {info['document_processor']['chunk_size']} å­—ç¬¦\n"
        text += f"**é‡å å¤§å°**: {info['document_processor']['chunk_overlap']} å­—ç¬¦\n\n"
        
        text += "### çŸ¥è¯†åº“çŠ¶æ€\n\n"
        if self.kb_loaded:
            text += f"**çŠ¶æ€**: âœ… å·²åŠ è½½\n"
            text += f"**æ–‡æ¡£å—æ•°é‡**: {info['retriever']['document_count']}\n"
        else:
            text += f"**çŠ¶æ€**: âš ï¸ æœªåŠ è½½\n"
        return text
    
    def get_available_models(self) -> List[Tuple[str, str]]:
        """è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹ (name as display, id as value)"""
        models = self.rag_system.config['models'].get('available_models', [])
        # è¿”å›æ ¼å¼: [(Description, Value), ...]
        # Value format: "provider:model_name"
        return [(f"{m['desc']} ({m['provider']})", f"{m['provider']}:{m['name']}") for m in models]

    def handle_model_change(self, selected_value: str):
        """å¤„ç†æ¨¡å‹åˆ‡æ¢"""
        if not selected_value:
            return "âŒ æ— æ•ˆé€‰æ‹©", self.get_system_info()
            
        try:
            provider, model_name = selected_value.split(":", 1)
            msg = self.rag_system.reload_generator(model_name, provider)
            return msg, self.get_system_info()
        except Exception as e:
            return f"âŒ åˆ‡æ¢å¤±è´¥: {e}", self.get_system_info()
    


    def create_interface(self):
        
        self.custom_css = """
        #chat-main { 
            height: 700px !important; 
            overflow-y: auto; 
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            background-color: #f9fafb;
        }
        
        #input-row { 
            margin-top: 10px;
        }
        
        #kb-table { 
            max-height: 300px !important; 
            overflow-y: auto; 
        }
        
        footer { visibility: hidden !important; }
        """

        with gr.Blocks(title="RAG æ™ºèƒ½åŠ©æ‰‹") as demo:
            
            with gr.Row():
                
                #å·¦ä¾§å†å²æ–‡ä»¶
                with gr.Column(scale=2, min_width=250):
                    gr.Markdown("### ğŸ—‚ï¸ å†å²ä¸æ–‡ä»¶")
                    
                    # å†å²è®°å½•
                    with gr.Group():
                        with gr.Row():
                            new_chat_btn = gr.Button("â• æ–°å¯¹è¯", variant="primary", size="sm")
                            refresh_chats_btn = gr.Button("ğŸ”„", size="sm", scale=0)
                        
                        chat_selector = gr.Dropdown(
                            label="å†å²è®°å½•",
                            choices=self.list_chats(),
                            interactive=True,
                            allow_custom_value=True,
                            container=False
                        )

                    gr.Markdown("---")
                    
                    # çŸ¥è¯†åº“ç®¡ç†
                    gr.Markdown("#### ğŸ“ çŸ¥è¯†åº“")
                    file_upload = gr.File(
                        label="ä¸Šä¼ æ–‡ä»¶",
                        file_count="multiple",
                        file_types=[".pdf", ".txt", ".docx", ".md"]
                    )
                    
                    with gr.Row():
                        upload_btn = gr.Button("ğŸ“¤ ä¸Šä¼ ", size="sm")
                        build_btn = gr.Button("ğŸ”¨ é‡å»ºåº“", size="sm")
                    
                    upload_status = gr.Textbox(show_label=False, placeholder="ç­‰å¾…æ“ä½œ...", interactive=False, lines=1)
                    
                    kb_table = gr.Dataframe(
                        headers=["æ–‡ä»¶å", "åˆ‡ç‰‡"],
                        datatype=["str", "number"],
                        value=self.refresh_kb_list(),
                        interactive=False,
                        elem_id="kb-table",
                        wrap=True
                    )
                    refresh_kb_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm")


                # ä¸­é—´æ ¸å¿ƒå¯¹è¯åŒº
                with gr.Column(scale=6):
                    # èŠå¤©æ¡†
                    chatbot = gr.Chatbot(
                        label=None,
                        show_label=False,
                        elem_id="chat-main"
                    )
                    
                    # è¾“å…¥åŒº
                    with gr.Row(elem_id="input-row"):
                        question_input = gr.Textbox(
                            show_label=False,
                            placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜... (Shift+Enter æ¢è¡Œ)",
                            scale=8,
                            lines=1,
                            max_lines=10,
                            autofocus=True,
                            container=False
                        )
                        submit_btn = gr.Button("å‘é€", variant="primary", scale=1, min_width=60)


                #å³ä¾§è®¾ç½®ä¿¡æ¯
                with gr.Column(scale=2, min_width=250):
                    gr.Markdown("### âš™ï¸ è®¾ç½®ä¸ç›‘æ§")
                    
                    # å‚æ•°è®¾ç½®
                    with gr.Group():
                        gr.Markdown("#### æ£€ç´¢è®¾ç½®")
                        top_k_slider = gr.Slider(
                            minimum=1, maximum=10, value=5, step=1, 
                            label="Top-K"
                        )
                    
                    with gr.Accordion("ğŸ“ Prompt è®¾ç½®", open=True):
                        prompt_input = gr.Textbox(
                            show_label=False,
                            value=self.rag_system.generator.PROMPT_TEMPLATE,
                            lines=10,
                            placeholder="System Prompt..."
                        )
                        reset_prompt_btn = gr.Button("æ¢å¤é»˜è®¤", size="sm")

                    gr.Markdown("---")
                    
                    # æ¨¡å‹é€‰æ‹©
                    gr.Markdown("#### ğŸ¤– æ¨¡å‹åˆ‡æ¢")
                    
                    # è·å–å½“å‰æ¨¡å‹ä½œä¸ºé»˜è®¤å€¼
                    current_llm = self.rag_system.config['models']['llm']
                    current_provider = current_llm.get('provider', 'huggingface')
                    if current_provider == 'ollama':
                         current_val = f"ollama:{current_llm.get('ollama', {}).get('model', '')}"
                    else:
                         current_val = f"huggingface:{current_llm.get('name', '')}"

                    model_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹",
                        choices=self.get_available_models(),
                        value=current_val,
                        interactive=True,
                        container=False
                    )
                    model_status = gr.Textbox(show_label=False, placeholder="æ¨¡å‹çŠ¶æ€...", lines=1, interactive=False)

                    gr.Markdown("---")

                    # ç³»ç»Ÿä¿¡æ¯
                    gr.Markdown("#### â„¹ï¸ ç³»ç»ŸçŠ¶æ€")
                    info_output = gr.Markdown(elem_id="sys_info")
                    refresh_info_btn = gr.Button("åˆ·æ–°çŠ¶æ€", size="sm")

            #äº‹ä»¶ç»‘å®šé€»è¾‘
            new_chat_btn.click(fn=self.handle_clear, outputs=[chatbot, question_input, chat_selector])

            submit_triggers = [question_input.submit, submit_btn.click]
            for trigger in submit_triggers:
                trigger(
                    fn=self.answer_question,
                    inputs=[question_input, chatbot, top_k_slider, prompt_input],
                    outputs=[chatbot, question_input, chat_selector]
                )

            reset_prompt_btn.click(fn=lambda: self.rag_system.generator.PROMPT_TEMPLATE, outputs=prompt_input)
            
            chat_selector.change(fn=self.load_chat, inputs=chat_selector, outputs=[chatbot, upload_status, chat_selector])
            refresh_chats_btn.click(fn=lambda: gr.update(choices=self.list_chats()), outputs=chat_selector)

            upload_btn.click(fn=self.upload_files, inputs=file_upload, outputs=upload_status).then(fn=self.refresh_kb_list, outputs=kb_table)
            build_btn.click(fn=self.build_kb_from_directory, outputs=upload_status).then(fn=self.refresh_kb_list, outputs=kb_table)
            refresh_kb_btn.click(fn=self.refresh_kb_list, outputs=kb_table)
            
            build_btn.click(fn=self.build_kb_from_directory, outputs=upload_status).then(fn=self.refresh_kb_list, outputs=kb_table)
            refresh_kb_btn.click(fn=self.refresh_kb_list, outputs=kb_table)
            
            model_dropdown.change(
                fn=self.handle_model_change,
                inputs=model_dropdown,
                outputs=[model_status, info_output]
            )
            
            demo.load(self.get_system_info, outputs=info_output)
            refresh_info_btn.click(fn=self.get_system_info, outputs=info_output)

        return demo


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–
    app = RAGWebApp()

    demo = app.create_interface()
    
    # å¯åŠ¨æœåŠ¡
    web_config = app.rag_system.config['web']
    demo.launch(
        server_name=web_config['host'],
        server_port=web_config['port'],
        share=web_config['share'],
        theme=gr.themes.Soft(),
        css=app.custom_css
    )


if __name__ == "__main__":
    main()
