[
  {
    "question": "什么是信息检索？",
    "answer": "信息检索是指从大规模、非结构化的数据集合中查找满足用户信息需求的过程。它是现代搜索引擎、推荐系统等应用的核心技术。",
    "contexts": [
      "信息检索系统简介\n\n什么是信息检索？\n\n信息检索（Information Retrieval, IR）是从大规模、非结构化的数据集合中查找满足用户信息需求的过程。它是现代搜索引擎、推荐系统等应用的核心技术。\n\n核心概念\n\n查询（Query）: 用户用自然语言或关键词表达的信息需求\n\n文档（Document）: 待检索的信息单元，可以是网页、文本、图片等\n\n相关性（Relevance）: 文档与查询之间的匹配程度\n\n检索模型（Retrieval Model）: 计算查询-文档相关性的数学模型\n\n经典检索模型\n\n1. 布尔模型\n\n最简单的检索模型\n\n基于集合论，使用AND、OR、NOT等逻辑运算符\n\n文档要么相关要么不相关，没有相关度的概念\n\n2. 向量空间模型（VSM）\n\n将文档和查询表示为向量\n\n使用TF-IDF权重\n\n通过余弦相似度计算相关性\n\n3. BM25模型\n\n基于概率检索模型\n\n考虑词频、文档长度归一化\n\n被广泛用于搜索引擎\n\n评价指标\n\n准确率（Precision）\n\nP = 检索到的相关文档数 / 检索到的文档总数\n\n衡量检索结果的准确性\n\n召回率（Recall）",
      "向量检索\n\n向量检索是现代信息检索的重要技术，特别适合语义检索场景。\n\nEmbedding技术\n\n将文本映射到高维向量空间\n\n语义相近的文本在向量空间中距离较近\n\n常用模型：BERT、BGE、Sentence-BERT等\n\n向量数据库\n\nFAISS：Facebook开源，适合单机部署\n\nMilvus：云原生向量数据库\n\nQdrant：高性能向量搜索引擎\n\nWeaviate：支持多模态检索\n\n相似度度量\n\n余弦相似度：常用于归一化向量\n\n欧氏距离：计算向量间的直线距离\n\n内积：点积运算\n\n实践应用\n\n企业知识库\n\nPDF文档检索\n\n内部文档问答\n\n知识管理系统\n\n智能客服\n\n自动回答常见问题\n\n基于历史对话检索\n\n多轮对话支持\n\n学术研究\n\n论文检索与推荐\n\n文献综述生成\n\n研究趋势分析",
      "衡量检索结果的准确性\n\n召回率（Recall）\n\nR = 检索到的相关文档数 / 相关文档总数\n\n衡量检索结果的完整性\n\nF1值\n\nF1 = 2 * (P * R) / (P + R)\n\n准确率和召回率的调和平均\n\nRAG技术\n\nRAG（Retrieval-Augmented Generation）是检索增强生成的缩写，是近年来兴起的一种结合信息检索和自然语言生成的技术。\n\nRAG的工作流程\n\n检索阶段：根据用户查询，从知识库中检索相关文档\n\n增强阶段：将检索到的文档作为上下文\n\n生成阶段：大语言模型基于上下文生成答案\n\nRAG的优势\n\n减少大模型幻觉（hallucination）\n\n提供可溯源的答案\n\n知识可更新，无需重新训练模型\n\n能处理特定领域知识\n\nRAG vs 传统检索\n\n特性 \n 传统检索 \n RAG \n \n 输出 \n 文档列表 \n 自然语言答案 \n \n 可读性 \n 需要用户自己阅读 \n 直接给出答案 \n \n 综合能力 \n 无 \n 可综合多个来源 \n \n 可解释性 \n 高（直接展示文档） \n 中（需要追溯来源）\n\n向量检索\n\n向量检索是现代信息检索的重要技术，特别适合语义检索场景。",
      "将你的课程资料（PDF、TXT、DOCX、Markdown等格式）放在这个目录下。\n\n系统会自动处理这些文档并构建知识库。",
      "source model (Nemotron-8B) and trained it using\na publicly available dataset, they observed a sig-\nnificant drop in accuracy on high-difficulty tasks\nlike MATH and AIME-24, despite a substantial\nreduction in length. Although reasoning models\nare rapidly developing, the accompanying training\ndatasets are rarely made public. Therefore, practi-\ntioners are often limited to using publicly available\ndatasets, whose difficulty may not match the ca-\npacity of state-of-the-art models. This is also the"
    ],
    "ground_truth": "信息检索是从大规模非结构化集合中寻找满足信息需求的材料（通常是文档）的过程。"
  },
  {
    "question": "RAG系统的全称是什么？",
    "answer": "RAG系统的全称为Retrieval-Augmented Generation。",
    "contexts": [
      "衡量检索结果的准确性\n\n召回率（Recall）\n\nR = 检索到的相关文档数 / 相关文档总数\n\n衡量检索结果的完整性\n\nF1值\n\nF1 = 2 * (P * R) / (P + R)\n\n准确率和召回率的调和平均\n\nRAG技术\n\nRAG（Retrieval-Augmented Generation）是检索增强生成的缩写，是近年来兴起的一种结合信息检索和自然语言生成的技术。\n\nRAG的工作流程\n\n检索阶段：根据用户查询，从知识库中检索相关文档\n\n增强阶段：将检索到的文档作为上下文\n\n生成阶段：大语言模型基于上下文生成答案\n\nRAG的优势\n\n减少大模型幻觉（hallucination）\n\n提供可溯源的答案\n\n知识可更新，无需重新训练模型\n\n能处理特定领域知识\n\nRAG vs 传统检索\n\n特性 \n 传统检索 \n RAG \n \n 输出 \n 文档列表 \n 自然语言答案 \n \n 可读性 \n 需要用户自己阅读 \n 直接给出答案 \n \n 综合能力 \n 无 \n 可综合多个来源 \n \n 可解释性 \n 高（直接展示文档） \n 中（需要追溯来源）\n\n向量检索\n\n向量检索是现代信息检索的重要技术，特别适合语义检索场景。",
      "将你的课程资料（PDF、TXT、DOCX、Markdown等格式）放在这个目录下。\n\n系统会自动处理这些文档并构建知识库。",
      "信息检索系统简介\n\n什么是信息检索？\n\n信息检索（Information Retrieval, IR）是从大规模、非结构化的数据集合中查找满足用户信息需求的过程。它是现代搜索引擎、推荐系统等应用的核心技术。\n\n核心概念\n\n查询（Query）: 用户用自然语言或关键词表达的信息需求\n\n文档（Document）: 待检索的信息单元，可以是网页、文本、图片等\n\n相关性（Relevance）: 文档与查询之间的匹配程度\n\n检索模型（Retrieval Model）: 计算查询-文档相关性的数学模型\n\n经典检索模型\n\n1. 布尔模型\n\n最简单的检索模型\n\n基于集合论，使用AND、OR、NOT等逻辑运算符\n\n文档要么相关要么不相关，没有相关度的概念\n\n2. 向量空间模型（VSM）\n\n将文档和查询表示为向量\n\n使用TF-IDF权重\n\n通过余弦相似度计算相关性\n\n3. BM25模型\n\n基于概率检索模型\n\n考虑词频、文档长度归一化\n\n被广泛用于搜索引擎\n\n评价指标\n\n准确率（Precision）\n\nP = 检索到的相关文档数 / 检索到的文档总数\n\n衡量检索结果的准确性\n\n召回率（Recall）",
      "focus.\nDLER successfully decoupled the \"length-\naccuracy\" trade-off. DLER was able to compress\nthe average inference length of the DeepSeek-R1-\n7B model from 7747 tokens to 2405 tokens (a\nreduction of about 69%), while simultaneously\nachieving superior accuracy across multiple key\nbenchmarks, such as MATH and AIME-24, com-\npared to the original model. This validated their\ncore argument: that the drawbacks of truncation-\nbased length penalties can be overcome through\nrefined RL optimization algorithms.",
      "ken via reinforcement learning. arXiv preprint\narXiv:2510.15110 .\nXinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan\nFang, and Xinchao Wang. 2025. Cot-valve: Length-\ncompressible chain-of-thought tuning. arXiv preprint\narXiv:2502.09601 .\nXin Men, Mingyu Xu, Qingyu Zhang, Bingning Wang,\nHongyu Lin, Yaojie Lu, Xianpei Han, and Weipeng\nChen. 2024. Shortgpt: Layers in large language\nmodels are more redundant than you expect. arXiv\npreprint arXiv:2403.03853 ."
    ],
    "ground_truth": "RAG的全称是Retrieval-Augmented Generation，即检索增强生成。"
  },
  {
    "question": "在RAG中，向量数据库的主要作用是什么？",
    "answer": "在RAG中，向量数据库的主要作用是在检索过程中存储和表示大量数据，以便于快速搜索和查找相关文档。同时，通过向量空间的建模，可以有效地实现语义相似度计算，从而提高检索效率。此外，向量数据库还能够更好地支持高级检索功能，如知识图谱检索、文档分类等。",
    "contexts": [
      "向量检索\n\n向量检索是现代信息检索的重要技术，特别适合语义检索场景。\n\nEmbedding技术\n\n将文本映射到高维向量空间\n\n语义相近的文本在向量空间中距离较近\n\n常用模型：BERT、BGE、Sentence-BERT等\n\n向量数据库\n\nFAISS：Facebook开源，适合单机部署\n\nMilvus：云原生向量数据库\n\nQdrant：高性能向量搜索引擎\n\nWeaviate：支持多模态检索\n\n相似度度量\n\n余弦相似度：常用于归一化向量\n\n欧氏距离：计算向量间的直线距离\n\n内积：点积运算\n\n实践应用\n\n企业知识库\n\nPDF文档检索\n\n内部文档问答\n\n知识管理系统\n\n智能客服\n\n自动回答常见问题\n\n基于历史对话检索\n\n多轮对话支持\n\n学术研究\n\n论文检索与推荐\n\n文献综述生成\n\n研究趋势分析",
      "衡量检索结果的准确性\n\n召回率（Recall）\n\nR = 检索到的相关文档数 / 相关文档总数\n\n衡量检索结果的完整性\n\nF1值\n\nF1 = 2 * (P * R) / (P + R)\n\n准确率和召回率的调和平均\n\nRAG技术\n\nRAG（Retrieval-Augmented Generation）是检索增强生成的缩写，是近年来兴起的一种结合信息检索和自然语言生成的技术。\n\nRAG的工作流程\n\n检索阶段：根据用户查询，从知识库中检索相关文档\n\n增强阶段：将检索到的文档作为上下文\n\n生成阶段：大语言模型基于上下文生成答案\n\nRAG的优势\n\n减少大模型幻觉（hallucination）\n\n提供可溯源的答案\n\n知识可更新，无需重新训练模型\n\n能处理特定领域知识\n\nRAG vs 传统检索\n\n特性 \n 传统检索 \n RAG \n \n 输出 \n 文档列表 \n 自然语言答案 \n \n 可读性 \n 需要用户自己阅读 \n 直接给出答案 \n \n 综合能力 \n 无 \n 可综合多个来源 \n \n 可解释性 \n 高（直接展示文档） \n 中（需要追溯来源）\n\n向量检索\n\n向量检索是现代信息检索的重要技术，特别适合语义检索场景。",
      "source model (Nemotron-8B) and trained it using\na publicly available dataset, they observed a sig-\nnificant drop in accuracy on high-difficulty tasks\nlike MATH and AIME-24, despite a substantial\nreduction in length. Although reasoning models\nare rapidly developing, the accompanying training\ndatasets are rarely made public. Therefore, practi-\ntioners are often limited to using publicly available\ndatasets, whose difficulty may not match the ca-\npacity of state-of-the-art models. This is also the",
      "将你的课程资料（PDF、TXT、DOCX、Markdown等格式）放在这个目录下。\n\n系统会自动处理这些文档并构建知识库。",
      "optimizing the training algorithm and modulating\nmodel parameters.\nOverall, these studies collectively demonstrate\nthat the \"continued optimization\" of pre-trained\nmodels is a research area rich in detail and highly\nproductive. By studying these works, we have not\nonly gained an understanding of the specific tech-\nnical paths to enhance model reliability, efficiency,\nand compactness but have also received valuable\ninspiration from their rigorous research paradigms\nand profound problem insights.\nReferences"
    ],
    "ground_truth": "向量数据库主要用于存储文档的向量化表示，并基于相似度计算实现快速的相关文档检索。"
  }
]